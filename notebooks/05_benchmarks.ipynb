{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54131077",
   "metadata": {},
   "source": [
    "# Test Set Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a341ae8",
   "metadata": {},
   "source": [
    "In this tutorial, we'll explore the test set generation module in Ragas to create a synthetic test set for a Retrieval-Augmented Generation (RAG)-based question-answering bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e705a1fd",
   "metadata": {},
   "source": [
    "To make sure our synthetic dataset is as realistic and diverse as possible, we will create different customer personas. Each persona will represent distinct traveler types and behaviors, helping us build a comprehensive and representative test set. This approach ensures that we can thoroughly evaluate the effectiveness and robustness of our RAG model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f1213",
   "metadata": {},
   "source": [
    "## Download and Load documents\n",
    "Run the command below to download the dummy Ragas Airline dataset and load the documents using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c945c6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# git clone https://huggingface.co/datasets/explodinggradients/ragas-airline-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec580955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"data/ragas-airline-dataset\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4b04b",
   "metadata": {},
   "source": [
    "## Set up the LLM and Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711dbbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/286d79g11513f730wt0d61kc0000gq/T/ipykernel_66285/1729561927.py:7: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "openai_client = openai.OpenAI()\n",
    "generator_embeddings = OpenAIEmbeddings(client=openai_client, model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd94c00",
   "metadata": {},
   "source": [
    "## Create Knowledge Graph\n",
    "Create a base knowledge graph with the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f90094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 9, relationships: 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562a8b4",
   "metadata": {},
   "source": [
    "## Setup the transforms\n",
    "In this tutorial, we create a Single Hop Query dataset using a knowledge graph built solely from nodes. To enhance our graph and improve query generation, we apply three key transformations:\n",
    "\n",
    "1. Headline Extraction: Uses a language model to extract clear section titles from each document (e.g., “Airline Initiated Cancellations” from flight cancellations.md). These titles isolate specific topics and provide direct context for generating focused questions.\n",
    "\n",
    "2. Headline Splitting: Divides documents into manageable subsections based on the extracted headlines. This increases the number of nodes and ensures more granular, context-specific query generation.\n",
    "\n",
    "3. Keyphrase Extraction: Identifies core thematic keyphrases (such as key seating information) that serve as semantic seed points, enriching the diversity and relevance of the generated queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b926d2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cd2457de9f4b08bc6237d081b337f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec63ee97df974eb8bc364de0b4f1b393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5dbdd292d2477faee77234296709b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying KeyphrasesExtractor:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'keyphrases' already exists in node 'ee3d35'. Skipping!\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.transforms import apply_transforms\n",
    "from ragas.testset.transforms import HeadlinesExtractor, HeadlineSplitter, KeyphrasesExtractor\n",
    "\n",
    "headline_extractor = HeadlinesExtractor(llm=generator_llm, max_num=20)\n",
    "headline_splitter = HeadlineSplitter(max_tokens=1500)\n",
    "keyphrase_extractor = KeyphrasesExtractor(llm=generator_llm)\n",
    "\n",
    "transforms = [\n",
    "    headline_extractor,\n",
    "    headline_splitter,\n",
    "    keyphrase_extractor\n",
    "]\n",
    "\n",
    "apply_transforms(kg, transforms=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9ef89",
   "metadata": {},
   "source": [
    "## Configuring Personas for Query Generation\n",
    "Personas provide context and perspective, ensuring that generated queries are natural, user-specific, and diverse. By tailoring queries to different user viewpoints, our test set covers a wide range of scenarios:\n",
    "\n",
    "* First Time Flier: Generates queries with detailed, step-by-step guidance, catering to newcomers who need clear instructions.\n",
    "* Frequent Flier: Produces concise, efficiency-focused queries for experienced travelers.\n",
    "* Angry Business Class Flier: Yields queries with a critical, urgent tone to reflect high expectations and immediate resolution demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a880c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import Persona\n",
    "\n",
    "persona_first_time_flier = Persona(\n",
    "    name=\"First Time Flier\",\n",
    "    role_description=\"Is flying for the first time and may feel anxious. Needs clear guidance on flight procedures, safety protocols, and what to expect throughout the journey.\",\n",
    ")\n",
    "\n",
    "persona_frequent_flier = Persona(\n",
    "    name=\"Frequent Flier\",\n",
    "    role_description=\"Travels regularly and values efficiency and comfort. Interested in loyalty programs, express services, and a seamless travel experience.\",\n",
    ")\n",
    "\n",
    "persona_angry_business_flier = Persona(\n",
    "    name=\"Angry Business Class Flier\",\n",
    "    role_description=\"Demands top-tier service and is easily irritated by any delays or issues. Expects immediate resolutions and is quick to express frustration if standards are not met.\",\n",
    ")\n",
    "\n",
    "personas = [persona_first_time_flier, persona_frequent_flier, persona_angry_business_flier]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e2e16",
   "metadata": {},
   "source": [
    "## Query Generation Using Synthesizers\n",
    "Synthesizers are responsible for converting enriched nodes and personas into queries. They achieve this by selecting a node property (e.g., \"entities\" or \"keyphrases\"), pairing it with a persona, style, and query length, and then using a LLM to generate a query-answer pair based on the content of the node.\n",
    "\n",
    "Two instances of the SingleHopSpecificQuerySynthesizer are used to define the query distribution:\n",
    "\n",
    "* Headlines-Based Synthesizer – Generates queries using extracted document headlines, leading to structured questions that reference specific sections.\n",
    "* Keyphrases-Based Synthesizer – Forms queries around key concepts, generating broader, thematic questions.\n",
    "\n",
    "Both synthesizers are weighted equally (0.5 each), ensuring a balanced mix of specific and conceptual queries, which ultimately enhances the diversity of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e669c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "query_distibution = [\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(llm=generator_llm, property_name=\"headlines\"),\n",
    "        0.5,\n",
    "    ),\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(\n",
    "            llm=generator_llm, property_name=\"keyphrases\"\n",
    "        ),\n",
    "        0.5,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8878cb",
   "metadata": {},
   "source": [
    "## Testset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea2ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    knowledge_graph=kg,\n",
    "    persona_list=personas,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "268a13f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba1160eb81e47ab8d198746c002ef30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d86fea881ef40caa874fd87168dc37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Ragas Airlines baggage policies I need to...</td>\n",
       "      <td>[Baggage Policies\\n\\nThis section provides a d...</td>\n",
       "      <td>Ragas Airlines' baggage policies include allow...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What should I do if my flight is delayed?</td>\n",
       "      <td>[Flight Delays\\n\\nFlight delays can be caused ...</td>\n",
       "      <td>If your flight is delayed, Ragas Airlines will...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What happens during Step 3: Refund Processing ...</td>\n",
       "      <td>[Flight Cancellations\\n\\nFlight cancellations ...</td>\n",
       "      <td>During Step 3: Refund Processing, refunds will...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How I change my booking?</td>\n",
       "      <td>[Managing Reservations\\n\\nManaging your reserv...</td>\n",
       "      <td>To change your booking, first check the fare r...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What happens if I don't request special assist...</td>\n",
       "      <td>[Special Assistance\\n\\nRagas Airlines provides...</td>\n",
       "      <td>If you did not request assistance in advance, ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the baggage restrictions for Ragas Ai...</td>\n",
       "      <td>[Baggage Policies\\n\\nThis section provides a d...</td>\n",
       "      <td>To avoid delays at security checkpoints, ensur...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What I do if my baggage is damaged?</td>\n",
       "      <td>[Delayed, Lost, or Damaged Baggage\\n\\nIf you e...</td>\n",
       "      <td>If your checked baggage arrives damaged, repor...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How I resubmit the claim if I miss documents?</td>\n",
       "      <td>[Potential Issues and Resolutions for Baggage ...</td>\n",
       "      <td>If your claim is denied due to missing documen...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wher r the compansation detals for my flight d...</td>\n",
       "      <td>[Flight Delays\\n\\nFlight delays can be caused ...</td>\n",
       "      <td>The compensation details will be included in t...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How can I claim compensation for additional ex...</td>\n",
       "      <td>[Passenger Responsibilities During Delays\\n\\nS...</td>\n",
       "      <td>To claim compensation for additional expenses ...</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What Ragas Airlines baggage policies I need to...   \n",
       "1          What should I do if my flight is delayed?   \n",
       "2  What happens during Step 3: Refund Processing ...   \n",
       "3                           How I change my booking?   \n",
       "4  What happens if I don't request special assist...   \n",
       "5  What are the baggage restrictions for Ragas Ai...   \n",
       "6                What I do if my baggage is damaged?   \n",
       "7      How I resubmit the claim if I miss documents?   \n",
       "8  Wher r the compansation detals for my flight d...   \n",
       "9  How can I claim compensation for additional ex...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [Baggage Policies\\n\\nThis section provides a d...   \n",
       "1  [Flight Delays\\n\\nFlight delays can be caused ...   \n",
       "2  [Flight Cancellations\\n\\nFlight cancellations ...   \n",
       "3  [Managing Reservations\\n\\nManaging your reserv...   \n",
       "4  [Special Assistance\\n\\nRagas Airlines provides...   \n",
       "5  [Baggage Policies\\n\\nThis section provides a d...   \n",
       "6  [Delayed, Lost, or Damaged Baggage\\n\\nIf you e...   \n",
       "7  [Potential Issues and Resolutions for Baggage ...   \n",
       "8  [Flight Delays\\n\\nFlight delays can be caused ...   \n",
       "9  [Passenger Responsibilities During Delays\\n\\nS...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Ragas Airlines' baggage policies include allow...   \n",
       "1  If your flight is delayed, Ragas Airlines will...   \n",
       "2  During Step 3: Refund Processing, refunds will...   \n",
       "3  To change your booking, first check the fare r...   \n",
       "4  If you did not request assistance in advance, ...   \n",
       "5  To avoid delays at security checkpoints, ensur...   \n",
       "6  If your checked baggage arrives damaged, repor...   \n",
       "7  If your claim is denied due to missing documen...   \n",
       "8  The compensation details will be included in t...   \n",
       "9  To claim compensation for additional expenses ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3  single_hop_specific_query_synthesizer  \n",
       "4  single_hop_specific_query_synthesizer  \n",
       "5  single_hop_specific_query_synthesizer  \n",
       "6  single_hop_specific_query_synthesizer  \n",
       "7  single_hop_specific_query_synthesizer  \n",
       "8  single_hop_specific_query_synthesizer  \n",
       "9  single_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distibution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60726a5e",
   "metadata": {},
   "source": [
    "# Non-English Testset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0938a",
   "metadata": {},
   "source": [
    "## Download and Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a0929",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# ! git clone https://huggingface.co/datasets/explodinggradients/Sample_non_english_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740320d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "\n",
    "path = \"data/Sample_non_english_corpus/\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad41caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327cb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Sample_non_english_corpus/New York.txt'}, page_content=\"New York (prononcé en anglais américain : /nu ˈjɔɹk/), officiellement nommée City of New York, connue également sous les noms et abréviations de New York City ou NYC (pour éviter la confusion avec l'État de New York), et dont le surnom le plus connu est The Big Apple (« La grosse pomme »), est la plus grande ville des États-Unis en nombre d'habitants et l'une des plus importantes du continent américain et du monde. Elle se situe dans le Nord-Est du pays, sur la côte atlantique, à l'extrémité sud-est de l'État de New York. La ville de New York se compose de cinq arrondissements appelés boroughs : Manhattan, Brooklyn, Queens, le Bronx et Staten Island. Ses habitants s'appellent les New-Yorkais (en anglais : New Yorkers).\\n\\nNew York exerce un impact significatif sur le commerce mondial, la finance, les médias, l'art, la mode, la recherche, la technologie, l'éducation, le divertissement et le tourisme, regroupant l'ensemble des caractéristiques d'une ville mondiale. Elle est parfois décrite comme la capitale du Monde ou la Ville des villes,. Si elle n'est plus la capitale fédérale des États-Unis depuis plus de deux siècles (elle occupe cette fonction de 1785 à 1790), New York alimente pendant quelques décennies une rivalité financière et politique avec Philadelphie.\\n\\nIl n'en reste pas moins que New York est la ville la plus peuplée du pays depuis 1790, avec 8 804 190 habitants selon le Bureau du recensement des États-Unis (recensement officiel de 2020) et la ville anglophone la plus peuplée au monde. Elle est aussi la troisième plus grande ville du continent américain derrière Mexico et São Paulo. Située au cœur de la mégalopole du BosWash, l'agglomération new-yorkaise (20 140 470 habitants) s'étend sur plusieurs comtés de l'État de New York (banlieues est et nord) et empiète sur deux États limitrophes. En effet, l'État du New Jersey comprend ses banlieues ouest et sud, et celui du Connecticut comprend ses banlieues nord-est. Son aire urbaine quant à elle, comptait 24 millions d'habitants en 2017. La ville et sa région métropolitaine constituent la première porte d'entrée pour l'immigration légale aux États-Unis. Pas moins de 170 langues sont parlées à New York, ce qui en fait la ville la plus linguistiquement diversifiée au monde. New York abrite plus de 3,2 millions de résidents nés à l'étranger, la plus grande population née à l'étranger de toutes les grandes villes du monde en 2016.\\n\\nAvec notamment Genève, Bâle et Strasbourg, New York est l'une des rares villes au monde à être le siège de plusieurs institutions internationales sans être capitale politique d’un État.\\n\\nNew York accueille quelque 50 millions de visiteurs annuellement,,. Times Square, « The Crossroads of the World (« Le carrefour du monde ») »,,, est l'une des intersections les plus populaires du monde, et le quartier des théâtres de Broadway est la plaque tournante du spectacle dans le pays tout entier et un centre majeur de l'industrie du divertissement dans le monde. La ville abrite un grand nombre de ponts et tunnels (789 en 2012), gratte-ciel et parcs de renommée mondiale.\\n\\nNew York se place en tête dans la triade des grands centres financiers mondiaux avec Londres et Hong Kong. Le quartier financier de New York, ancré par Wall Street dans le Lower Manhattan, fonctionne ainsi comme la « capitale financière du monde »,,,,,, abritant les deux plus grandes bourses du monde par capitalisation, le New York Stock Exchange (Bourse de New York) et le NASDAQ, tandis que le nouveau One World Trade Center est le plus haut gratte-ciel d'Amérique du Nord. De plus, le marché immobilier de Manhattan est parmi les plus chers au monde. New York abrite également le plus grand nombre de milliardaires de toutes les villes du monde,.\\n\\nNew York est frappée le 11 septembre 2001 par le plus grave attentat ayant jamais touché les États-Unis : deux avions de ligne détournés par des terroristes membres d'Al-Qaïda percutent les tours jumelles du World Trade Center et les détruisent entièrement. En 2021, la reconstruction du quartier n'est pas encore achevée. New York est l'une des villes les plus cosmopolites du monde, par ses nombreux quartiers ethniques. Les plus connus sont Little Italy, ou encore Chinatown qui intègre la plus forte concentration de population chinoise des Amériques,,,.\\n\\nEnfin, New York accueille des institutions d'importance mondiale. On peut notamment citer le siège de l'ONU, ce qui en fait un centre majeur pour la diplomatie internationale,, mais aussi de nombreux sièges de multinationales, des centres culturels tels que le Metropolitan Museum of Art, le Brooklyn Museum, le Museum of Modern Art, le Lincoln Center et des salles de spectacle de renommée mondiale comme le Madison Square Garden. De nombreuses universités réputées sont situées à New York, notamment l'université de la ville de New York, l'université Columbia, l'université de New York, et l'université Rockefeller, qui sont classées parmi les 50 meilleures universités du monde.\"),\n",
       " Document(metadata={'source': 'Sample_non_english_corpus/Pékin.txt'}, page_content=\"Pékin, /pe.kɛ̃/  (chinois : 北京 ; pinyin : Běijīng /pe˨˩˦i.tɕi˥ŋ/ , litt. « capitale du nord »), ou Beijing,, est la capitale de la république populaire de Chine. Située dans le Nord-Est du pays, la municipalité de Pékin, d'une superficie de 16 800 km2, est entourée par la province du Hebei ainsi que la municipalité de Tianjin, qui forment la mégalopole de Jing-Jin-Ji. Pékin est considérée comme le centre politique et culturel de la Chine, tandis que Hong Kong, Shanghai, Canton et Shenzhen dominent sur le plan économique.\\n\\nD'abord ville périphérique de l'empire chinois sous les dynasties Han et les Tang, elle prend de l'importance lorsque les peuples Jürchen, qui fondent la dynastie Jin, la choisissent comme leur capitale principale en 1153. Le prince mongol Kubilai Khan en fait de même sous le nom de Dadu (« grande métropole »), enfin la dynastie Ming y transfère son administration en 1421, parachevant le choix de Pékin comme capitale de la Chine. Située à proximité de la Grande Muraille, Pékin abrite des monuments célèbres comme la Cité interdite et le Temple du Ciel, qui sont inscrits au patrimoine mondial. De nombreuses réalisations architecturales et structurelles ont modifié la ville à l'occasion des Jeux olympiques d'été dont elle a été l'hôte en 2008. Pékin a été choisie par le CIO pour organiser les Jeux olympiques d'hiver de 2022 et a donc été la première ville à avoir accueilli les deux éditions de l'évènement sportif international.\\n\\nSes 21,3 millions d'habitants classent Pékin  deuxième ville de Chine après Shanghai. La zone urbaine compte quant à elle 19,4 millions d'habitants. Le parler pékinois forme la base du mandarin standard. D'un point de vue économique, Pékin est la deuxième ville de Chine par le PIB total derrière Shanghai.\"),\n",
       " Document(metadata={'source': 'Sample_non_english_corpus/Londres.txt'}, page_content=\"Londres (/lɔ̃dʁ/  ; en anglais : London, /ˈlʌndən/ ) est la capitale et plus grande ville d'Angleterre et du Royaume-Uni,. La ville est située près de l'estuaire de la Tamise dans le sud-est de l'Angleterre. Londinium est fondée par les Romains il y a presque 2 000 ans. La Cité de Londres, le noyau historique de Londres avec une superficie de seulement 1,12 mile carré (2,9 km2) conserve des frontières qui suivent de près ses limites médiévales. Londres est gouvernée par le maire de Londres et l'Assemblée de Londres.\\n\\nLondres est considérée comme l'une des villes mondiales parmi les plus importantes,,,. La ville exerce un impact considérable sur les arts, le commerce, l'éducation, le divertissement, la mode, les finances, les soins de santé, les médias, les services professionnels, la recherche et le développement, le tourisme et les transports,. Londres se classe 26e sur 300 grandes villes pour ses performances économiques. La City de Londres est l'un des plus grands centres financiers, elle est classée troisième en 2023 derrière New York et Shanghai,\\n\\n, et a le plus gros PIB urbain en Europe en 2017, estimé à 801,66 milliards d'euros,. En 2011 elle est la ville la plus visitée mesurée par les arrivées internationales et possède le système aéroportuaire le plus fréquenté par le trafic de passagers du monde en 2020. Elle est la première destination d'investissement en 2017, et est la ville, en 2015, avec le plus de particuliers avec une situation nette au-dessus de 30 millions de dollars. Les 43 universités de Londres forment la plus grande concentration d'instituts d'enseignement supérieur en Europe, et Londres abrite des institutions réputées comme l'Imperial College London en sciences naturelles et appliquées, la London School of Economics en sciences sociales,,. En 2012, Londres est devenue la première ville à avoir accueilli trois Jeux olympiques d'été modernes.\\n\\nLa région de Londres, composée de l'Inner London et de l'Outer London, comptait environ 8 908 000 habitants en 2018 et réalise un cinquième du produit intérieur brut du Royaume-Uni. En 2018, l'aire urbaine de Londres comptait 9 787 426 habitants. En 2018, Eurostat estime que son aire métropolitaine est peuplée de 14 257 962 habitants, la plus peuplée de l'Union européenne quand le pays en faisait encore partie. En Europe,\\n\\nelle est la troisième agglomération après Moscou et Istanbul et la 25e mondiale. Ses habitants s'appellent les Londoniens (en anglais : Londoners).\\n\\nLondres contient quatre sites du patrimoine mondial : la tour de Londres ; Kew Gardens ; le site comprenant le palais de Westminster, l'abbaye de Westminster et l'église Sainte-Marguerite ; et le village historique de Greenwich où l'Observatoire royal de Greenwich définit le premier méridien (0 ° de longitude) et l'heure moyenne de Greenwich. Les autres monuments incluent le palais de Buckingham, le London Eye, Piccadilly Circus, la cathédrale Saint-Paul, Tower Bridge, Trafalgar Square et The Shard. Londres possède de nombreux musées, galeries, bibliothèques dont le British Museum, la National Gallery, le Natural History Museum, le Tate Modern, la British Library. Le métro de Londres est le plus ancien réseau ferroviaire souterrain du monde.\"),\n",
       " Document(metadata={'source': 'Sample_non_english_corpus/Madrid.txt'}, page_content=\"Madrid (prononcé : /ma.dʁid/  ; en espagnol : [maˈðɾið]) est la capitale et la plus grande ville d'Espagne. Située dans la partie centrale du royaume, elle est également la capitale et la ville la plus peuplée de la communauté de Madrid. En tant que capitale d'État, elle abrite la plupart des institutions politiques du pays, dont la résidence royale, le siège du gouvernement et le Parlement.\\n\\nElle compte une population d'environ 3,4 millions d'habitants intra-muros sur une superficie totale de 604,3 km2, au sein d'une aire urbaine d'environ 6,5 millions d'habitants en 2014. En comptant sa population intra-muros, Madrid est la deuxième ville de l'Union européenne, après Berlin.\\n\\nVille mondiale, elle abrite le siège de nombreuses institutions, dont l'Organisation mondiale du tourisme, l'Organisation des États ibéro-américains, l'Académie royale espagnole et l'Institut Cervantes. Considérée comme l'une des principales places financières de l'Europe du Sud, elle partage le statut de cœur économique de l'Espagne avec Barcelone. Elle accueille le siège social des plus grandes entreprises du pays, comme Telefónica, Repsol ou Iberia.\\n\\nLes bâtiments d'architecture récente côtoient des constructions de style néo-classique, telles que la porte d'Alcalá, la place de Cybèle ou la cathédrale de l'Almudena. Ville d'art, ses trois principaux musées, le musée du Prado, le musée Reina Sofía et le musée Thyssen-Bornemisza, comptent parmi les plus visités au monde. En outre, Madrid abrite deux des plus grands clubs de football au monde, le Real Madrid et l'Atlético de Madrid.\"),\n",
       " Document(metadata={'source': 'Sample_non_english_corpus/Tokyo.txt'}, page_content=\"Tokyo, officiellement Métropole de Tokyo, est de facto la capitale du Japon, ainsi que l'une de ses 47 préfectures. Ses plus de 14 000 000 habitants font de Tokyo la préfecture japonaise la plus peuplée. Le Grand Tokyo, constitué des préfectures bordant la baie de Tokyo, est l'aire urbaine la plus peuplée au monde avec 40 800 000 habitants.\\n\\nTokyo est située sur la côte méridionale de Honshū, l'île principale de l'archipel japonais. La ville est le principal centre politique de l'archipel depuis le XVIIe siècle. Elle accueille la plupart des institutions du pays : la résidence principale de l'empereur du Japon, du Premier ministre, le siège de la Diète (le parlement japonais), du Cabinet, les ministères qui le constituent ainsi que toutes les ambassades étrangères.\\n\\nÀ l'origine, Tokyo n’était qu’un petit village de pêcheurs nommé Edo. Fortifié au XVe siècle, Edo devient la base militaire du shogun Tokugawa Ieyasu à la fin du XVIe siècle, puis la capitale de son gouvernement féodal. Durant l'époque d'Edo (1603-1868), la ville se développe et devient l'une des plus peuplées au monde à la fin du XVIIIe siècle, avec une population de près d'un million d'habitants. Avec la restauration de l'empereur en 1868, elle est confortée dans son rôle de cœur politique du Japon : le château d'Edo devient la résidence de l'empereur Meiji (Kōkyo) et la ville acquiert son nom actuel par opposition à Kyoto, l'ancienne capitale. Elle est ravagée en 1923 par un séisme de magnitude 7,9 qui fait plus de 100 000 morts. Durant la Seconde Guerre mondiale, elle est détruite pour moitié par des bombardements aériens américains. Les bombes incendiaires embrasent la ville et font plus de 100 000 victimes. La ville est rapidement reconstruite après la guerre.\\n\\nDans la seconde moitié du XXe siècle, Tokyo devient une métropole de rang mondial grâce à un fort développement industriel — notamment dans l'électronique — et voit sa population multipliée par dix en cinquante ans.\\n\\nPrincipal centre économique et financier du Japon, Tokyo est l'une des principales places financières asiatiques et mondiales. Elle est la première ville mondiale en ce qui concerne les produits urbains bruts. Le dynamique arrondissement de Shinjuku comporte de nombreux gratte-ciels, dont la mairie de la ville, et plusieurs grands magasins du Japon. Minato-ku accueille les sièges sociaux de multiples entreprises japonaises et étrangères, ainsi qu'une cinquantaine d'ambassades. Chiyoda concentre pour sa part les institutions politiques japonaises. Enfin, Shibuya est réputé être l'un des quartiers les plus animés de la ville, grâce à la présence de grands centres commerciaux comme le 109. Malgré la modernité de son architecture, dont témoigne la tour Tokyo Skytree, bien des sanctuaires shinto et temples bouddhistes ont été reconstruits ou, pour quelques-uns, partiellement préservés après les bombardements, comme le Sensō-ji, le sanctuaire Yasukuni, le Zōjō-ji ou la porte Hōzōmon.\\n\\nSituée au fond de la baie de Tokyo, Tokyo dispose d'un statut administratif particulier, la ville de Tokyo et la préfecture de Tokyo ayant fusionné en 1943. L'agglomération de Tokyo, qui va bien au-delà des limites de la préfecture, s'étend sur une large frange de la baie de Tokyo ainsi que sur la région du Kantō. Elle constitue en outre le pôle principal de la « mégalopole japonaise », avec notamment Osaka et Nagoya. La préfecture a organisé les Jeux olympiques d'été de 1964 et de 2021.\\n\\nEn 2021, Tokyo est considérée comme la troisième ville mondiale selon le classement Global Power City Index. Elle est la quatrième ville mondiale dans le classement du cabinet de conseil Kearney.\"),\n",
       " Document(metadata={'source': 'Sample_non_english_corpus/Sydney.txt'}, page_content=\"Sydney (prononcé en français /sid.nɛ/ ; en anglais /ˈsɪd.ni/ ) est la ville la plus peuplée d'Australie et du continent océanien, ainsi que la capitale de l'État de Nouvelle-Galles du Sud (mais elle n’est pas la capitale de l’Australie contrairement à une idée reçue). Elle est située dans le Sud-Est du pays, sur les rives de la mer de Tasman. Avec une aire urbaine comprenant, en 2016, une population de 4 823 991 habitants sur près de 12 300 km2, Sydney se place devant Melbourne et Brisbane pour ce qui est du nombre d'habitants. Ses habitants s'appellent les Sydneyites ou Sydneysiders en anglais et les Sydnéens en français.\\n\\nUn peuplement aborigène a existé sur le site pendant plusieurs millénaires. L'explorateur James Cook accoste pour la première fois en Australie en 1770 sur le site de Botany Bay. Première des colonies européennes d'Australie, Sydney est fondée en 1788 à Sydney Cove (à l'emplacement actuel de Circular Quay) par le capitaine Arthur Phillip, commandant de la première flotte venant de Grande-Bretagne, pour en faire une colonie pénitentiaire. La découverte de gisements d'or dans l'État voisin du Victoria au début de la seconde moitié du XIXe siècle entraîne le développement de la ville. En 1920, Sydney compte plus d'un million d'habitants et s'étend bien au-delà de la baie de Port Jackson, son site initial. Pendant la Seconde Guerre mondiale, la ville sert de base pour les forces aériennes et navales alliées. En mai et juin 1942, elle est victime d'un bombardement par des sous-marins japonais qui détruisent le port.\\n\\nDurant la seconde moitié du XXe siècle, Sydney devient peu à peu le cœur économique de l'Australie et le principal centre financier de l'Océanie. Barangaroo et le centre d'affaires de Sydney (plus familièrement appelé « The City » par les habitants) accueillent ainsi de nombreux gratte-ciels — la World Tower et la Sydney Tower notamment — et sièges sociaux d'entreprises, mais aussi de vastes parcs, comme Hyde Park ou les Royal Botanic Gardens. Darlinghurst est le quartier gay de la ville ; les banlieues de Woolloomooloo et Glebe, au nord du centre-ville, sont des quartiers en pleine gentrification. Sydney est en outre une destination touristique internationale, connue aussi bien pour son quartier central historique The Rocks que pour ses deux monuments principaux, l'opéra et le Harbour Bridge. Elle comprend les plus grands musées d'Australie, tels l'Australian Museum, la Galerie d'art de Nouvelle-Galles du Sud et le musée de Sydney, le zoo de Taronga et le Luna Park, l'un des plus anciens parcs d'attractions au monde.\\n\\nSydney accueille de grands événements comme les Jeux olympiques d'été de 2000 ou les journées mondiales de la jeunesse 2008. Des millions de touristes viennent chaque année pour visiter les monuments de la ville. Sydney est aussi la porte pour l'Australie pour de nombreux visiteurs. La baie de Sydney, le parc national Royal et de Sydney Harbour, la cathédrale Saint-André et Sainte-Marie et la plage de Bondi sont des lieux d’intérêts de la ville. Sydney est le deuxième siège après Canberra du gouvernement australien, ainsi que deuxième lieu officiel de résidence du gouverneur général et du Premier ministre d'Australie. 250 langues différentes sont parlées dans la ville et un tiers des habitants parle une autre langue que l'anglais chez eux.\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f9bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/286d79g11513f730wt0d61kc0000gq/T/ipykernel_83022/3822447560.py:8: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper, llm_factory\n",
    "from ragas.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "generator_embeddings = OpenAIEmbeddings(client=openai_client, model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca322a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import Persona\n",
    "\n",
    "personas = [\n",
    "    Persona(\n",
    "        name=\"curious student\",\n",
    "        role_description=\"A student who is curious about the world and wants to learn more about different cultures and languages\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174adbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms.extractors.llm_based import NERExtractor, HeadlinesExtractor\n",
    "from ragas.testset.transforms.splitters import HeadlineSplitter\n",
    "\n",
    "headline_extractor = HeadlinesExtractor(llm=generator_llm, max_num=20)\n",
    "headline_splitter = HeadlineSplitter(max_tokens=1500)\n",
    "ner_extractor = NERExtractor(llm=generator_llm)\n",
    "\n",
    "transforms = [\n",
    "    headline_extractor,\n",
    "    headline_splitter,\n",
    "    ner_extractor\n",
    "]\n",
    "\n",
    "#transforms = [HeadlinesExtractor(), HeadlineSplitter(), NERExtractor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e0a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm, embedding_model=generator_embeddings, persona_list=personas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4235735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0),\n",
    "]\n",
    "\n",
    "for query, _ in distribution:\n",
    "    prompts = await query.adapt_prompts(\"spanish\", llm=generator_llm)\n",
    "    query.set_prompts(**prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f7a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4cb7d416e2497aa78e4b8649ec3f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb0799c1db243d4a3e6cbfb0c0b3cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f24652d95d44d61b7585d78b54e2cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying NERExtractor:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'entities' already exists in node '998d5c'. Skipping!\n",
      "Property 'entities' already exists in node '02a4d1'. Skipping!\n",
      "Property 'entities' already exists in node '3f8eb0'. Skipping!\n",
      "Property 'entities' already exists in node '8e7810'. Skipping!\n",
      "Property 'entities' already exists in node '206565'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd3dc4bc4514def83cd7429d9d1e286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003c38192f224b34a7a46a834135305f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs[:],\n",
    "    testset_size=5,\n",
    "    transforms=transforms,\n",
    "    query_distribution=distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad029a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = dataset.to_evaluation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbf4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Qu'est-ce que Manhatten et pourquoi est-ce un endroit si important dans la ville de New York?\n",
      "Reference: Manhattan est l'un des cinq arrondissements de New York, qui est la plus grande ville des États-Unis. Il est particulièrement connu pour son quartier financier, ancré par Wall Street, qui fonctionne comme la 'capitale financière du monde'. De plus, Manhattan abrite le marché immobilier parmi les plus chers au monde et le plus grand nombre de milliardaires de toutes les villes du monde. C'est également un centre majeur de l'industrie du divertissement, avec des attractions comme Times Square et Broadway.\n"
     ]
    }
   ],
   "source": [
    "print(\"Query:\", eval_dataset[0].user_input)\n",
    "print(\"Reference:\", eval_dataset[0].reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e52f9",
   "metadata": {},
   "source": [
    "# How to Evaluate and Improve a RAG App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a4c10",
   "metadata": {},
   "source": [
    "## Necesary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b764336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from langchain_classic.docstore.document import Document\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever as LangchainBM25Retriever\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ff209",
   "metadata": {},
   "source": [
    "## Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0fa48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Retriever:\n",
    "    \"\"\"Simple BM25-based retriever for document search.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_name=\"m-ric/huggingface_doc\", default_k=3):\n",
    "        self.default_k = default_k\n",
    "        self.retriever = self._build_retriever(dataset_name)\n",
    "    \n",
    "    def _build_retriever(self, dataset_name: str) -> LangchainBM25Retriever:\n",
    "        \"\"\"Build a BM25 retriever from HuggingFace docs.\"\"\"\n",
    "        knowledge_base = datasets.load_dataset(dataset_name, split=\"train\")\n",
    "        \n",
    "        # Create documents\n",
    "        source_documents = [\n",
    "            Document(\n",
    "                page_content=row[\"text\"],\n",
    "                metadata={\"source\": row[\"source\"].split(\"/\")[1]},\n",
    "            )\n",
    "            for row in knowledge_base\n",
    "        ]\n",
    "        \n",
    "        # Split documents\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "        )\n",
    "        \n",
    "        all_chunks = []\n",
    "        for document in source_documents:\n",
    "            chunks = text_splitter.split_documents([document])\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        # Simple deduplication\n",
    "        unique_chunks = []\n",
    "        seen_content = set()\n",
    "        for chunk in all_chunks:\n",
    "            if chunk.page_content not in seen_content:\n",
    "                seen_content.add(chunk.page_content)\n",
    "                unique_chunks.append(chunk)\n",
    "        \n",
    "        return LangchainBM25Retriever.from_documents(\n",
    "            documents=unique_chunks,\n",
    "            k=1,  # Will be overridden by retrieve method\n",
    "        )\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = None):\n",
    "        \"\"\"Retrieve documents for a given query.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "        self.retriever.k = top_k\n",
    "        return self.retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3f388",
   "metadata": {},
   "source": [
    "## Define Simple RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "class RAG:\n",
    "    \"\"\"Simple RAG system for document retrieval and answer generation.\"\"\"\n",
    "\n",
    "    def __init__(self, llm_client: AsyncOpenAI, retriever: BM25Retriever, system_prompt=None, model=\"gpt-4o-mini\", default_k=3):\n",
    "        self.llm_client = llm_client\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "        self.default_k = default_k\n",
    "        self.system_prompt = system_prompt or \"Answer only based on documents. Be concise.\\n\\nQuestion: {query}\\nDocuments:\\n{context}\\nAnswer:\"\n",
    "\n",
    "    async def query(self, question: str, top_k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Query the RAG system.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "\n",
    "        return await self._naive_query(question, top_k)\n",
    "\n",
    "    async def _naive_query(self, question: str, top_k: int) -> Dict[str, Any]:\n",
    "        \"\"\"Handle naive RAG: retrieve once, then generate.\"\"\"\n",
    "        # 1. Retrieve documents using BM25\n",
    "        docs = self.retriever.retrieve(question, top_k)\n",
    "\n",
    "        if not docs:\n",
    "            return {\"answer\": \"No relevant documents found.\", \"retrieved_documents\": [], \"num_retrieved\": 0}\n",
    "\n",
    "        # 2. Build context from retrieved documents\n",
    "        context = \"\\n\\n\".join([f\"Document {i}:\\n{doc.page_content}\" for i, doc in enumerate(docs, 1)])\n",
    "        prompt = self.system_prompt.format(query=question, context=context)\n",
    "\n",
    "        # 3. Generate response using OpenAI with retrieved context\n",
    "        response = await self.llm_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content.strip(),\n",
    "            \"retrieved_documents\": [{\"content\": doc.page_content, \"metadata\": doc.metadata, \"document_id\": i} for i, doc in enumerate(docs)],\n",
    "            \"num_retrieved\": len(docs)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d69eb",
   "metadata": {},
   "source": [
    "## Create evaluation dataset\n",
    "\n",
    "We'll use `huggingface_doc_qa_eval`, a dataset of questions and answers about Hugging Face documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61963190",
   "metadata": {},
   "source": [
    "The evaluation script downloads the dataset from here and converts it into Ragas Dataset format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eda1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from ragas import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "def download_and_save_dataset() -> Path:\n",
    "    dataset_path = Path(\"datasets/hf_doc_qa_eval.csv\")\n",
    "    dataset_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "    if not dataset_path.exists():\n",
    "        github_url = \"https://raw.githubusercontent.com/explodinggradients/ragas/main/examples/ragas_examples/improve_rag/datasets/hf_doc_qa_eval.csv\"\n",
    "        urllib.request.urlretrieve(github_url, dataset_path)\n",
    "\n",
    "    return dataset_path\n",
    "\n",
    "def create_ragas_dataset(dataset_path: Path) -> Dataset:\n",
    "    dataset = Dataset(name=\"hf_doc_qa_eval\", backend=\"local/csv\", root_dir=\".\")\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        dataset.append({\"question\": row[\"question\"], \"expected_answer\": row[\"expected_answer\"]})\n",
    "\n",
    "    dataset.save()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5b8c3",
   "metadata": {},
   "source": [
    "## Set up metrics for RAG evaluation\n",
    "Now that we have our evaluation dataset ready, we need metrics to measure RAG performance. Start with simple, focused metrics that directly measure your core use case.\n",
    "\n",
    "Here we use a correctness discrete metric that evaluates whether the RAG response contains the key information from the expected answer and is factually accurate based on the provided context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import DiscreteMetric\n",
    "\n",
    "# Define correctness metric\n",
    "correctness_metric = DiscreteMetric(\n",
    "    name=\"correctness\",\n",
    "    prompt=\"\"\"Compare the model response to the expected answer and determine if it's correct.\n",
    "\n",
    "Consider the response correct if it:\n",
    "1. Contains the key information from the expected answer\n",
    "2. Is factually accurate based on the provided context\n",
    "3. Adequately addresses the question asked\n",
    "\n",
    "Return 'pass' if the response is correct, 'fail' if it's incorrect.\n",
    "\n",
    "Question: {question}\n",
    "Expected Answer: {expected_answer}\n",
    "Model Response: {response}\n",
    "\n",
    "Evaluation:\"\"\",\n",
    "    allowed_values=[\"pass\", \"fail\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc281b",
   "metadata": {},
   "source": [
    "Now that we have our evaluation metric, we need to run it systematically across our dataset. This is where Ragas experiments come in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c81115",
   "metadata": {},
   "source": [
    "## Create the evaluation experiment\n",
    "The experiment function runs your RAG system on each data sample and evaluates the response using our correctness metric.\n",
    "\n",
    "The experiment function takes a dataset row containing the question, expected context, and expected answer, then:\n",
    "\n",
    "1. Queries the RAG system with the question\n",
    "2. Evaluates the response using the correctness metric\n",
    "3. Returns detailed results including scores and reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72767fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "from ragas import experiment\n",
    "\n",
    "\n",
    "@experiment()\n",
    "async def evaluate_rag(row: Dict[str, Any], rag: RAG, llm) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run RAG evaluation on a single row.\n",
    "\n",
    "    Args:\n",
    "        row: Dictionary containing question and expected_answer\n",
    "        rag: Pre-initialized RAG instance\n",
    "        llm: Pre-initialized LLM client for evaluation\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with evaluation results\n",
    "    \"\"\"\n",
    "    question = row[\"question\"]\n",
    "\n",
    "    # Query the RAG system\n",
    "    rag_response = await rag.query(question, top_k=4)\n",
    "    model_response = rag_response.get(\"answer\", \"\")\n",
    "\n",
    "    # Evaluate correctness asynchronously\n",
    "    score = await correctness_metric.ascore(\n",
    "        question=question,\n",
    "        expected_answer=row[\"expected_answer\"],\n",
    "        response=model_response,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Return evaluation results\n",
    "    result = {\n",
    "        **row,\n",
    "        \"model_response\": model_response,\n",
    "        \"correctness_score\": score.value,\n",
    "        \"correctness_reason\": score.reason,\n",
    "        \"mlflow_trace_id\": rag_response.get(\"mlflow_trace_id\", \"N/A\"),  # MLflow trace ID for debugging (explained later)\n",
    "        \"retrieved_documents\": [\n",
    "            doc.get(\"content\", \"\")[:200] + \"...\" if len(doc.get(\"content\", \"\")) > 200 else doc.get(\"content\", \"\")\n",
    "            for doc in rag_response.get(\"retrieved_documents\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98c7f7",
   "metadata": {},
   "source": [
    "With our dataset, metrics, and experiment function ready, we can now evaluate our RAG system's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e27d59",
   "metadata": {},
   "source": [
    "## Run initial RAG experiment\n",
    "Now let's run the complete evaluation pipeline to get baseline performance metrics for our RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74dc5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required components\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from openai import AsyncOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.llms import llm_factory\n",
    "import os\n",
    "\n",
    "async def run_evaluation():\n",
    "    # Download and prepare dataset\n",
    "    dataset_path = download_and_save_dataset()\n",
    "    dataset = create_ragas_dataset(dataset_path)\n",
    "\n",
    "    # Initialize RAG components\n",
    "    openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    retriever = BM25Retriever()\n",
    "    rag = RAG(llm_client=openai_client, retriever=retriever)\n",
    "    llm = llm_factory('gpt-4o-mini', client=openai_client)\n",
    "\n",
    "    # Run evaluation experiment\n",
    "    exp_name = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_naiverag\"\n",
    "    results = await evaluate_rag.arun(\n",
    "        dataset, \n",
    "        name=exp_name,\n",
    "        rag=rag,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    if results:\n",
    "        pass_count = sum(1 for result in results if result.get(\"correctness_score\") == \"pass\")\n",
    "        total_count = len(results)\n",
    "        pass_rate = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
    "        print(f\"Results: {pass_count}/{total_count} passed ({pass_rate:.1f}%)\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|██████████| 66/66 [01:05<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 43/66 passed (65.2%)\n",
      "Experiment(name=20251111-230933_naiverag,  len=66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "results = await run_evaluation()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762ff0f",
   "metadata": {},
   "source": [
    "This downloads the dataset, initializes the BM25 retriever, runs the evaluation experiment on each sample, and saves detailed results to the experiments/ directory as CSV files for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabecce7",
   "metadata": {},
   "source": [
    "With a `65.2%` pass rate, we now have a baseline. The detailed results CSV in experiments/ now contains all the data we need for error analysis and systematic improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec71ec5",
   "metadata": {},
   "source": [
    "## Improve the RAG app\n",
    "With retrieval identified as the primary bottleneck, we can improve our system in two ways:\n",
    "\n",
    "Traditional approaches focus on better chunking, hybrid search, or vector embeddings. However, since our BM25 retrieval consistently misses relevant documents with single queries, we'll explore an agentic approach instead.\n",
    "\n",
    "`Agentic RAG` lets the AI iteratively refine its search strategy - trying multiple search terms and deciding when it has found sufficient context, rather than relying on one static query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba4b6d",
   "metadata": {},
   "source": [
    "## Agentic RAG implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb0637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedRAG(RAG):\n",
    "    \"\"\"RAG system that can operate in naive or agentic mode.\"\"\"\n",
    "\n",
    "    def __init__(self, llm_client: AsyncOpenAI, retriever: BM25Retriever, mode=\"agentic\", system_prompt=None, model=\"gpt-5-mini\", default_k=3):\n",
    "        super().__init__(\n",
    "            llm_client=llm_client,\n",
    "            retriever=retriever,\n",
    "            system_prompt=system_prompt,\n",
    "            model=model,\n",
    "            default_k=default_k\n",
    "        )\n",
    "        self.mode = mode.lower()\n",
    "        self._agent = None\n",
    "        \n",
    "        if self.mode == \"agentic\":\n",
    "            self._setup_agent()\n",
    "\n",
    "    def _setup_agent(self):\n",
    "        \"\"\"Setup agent for agentic mode.\"\"\"\n",
    "        try:\n",
    "            from agents import Agent, function_tool\n",
    "        except ImportError:\n",
    "            raise ImportError(\"agents package required for agentic mode\")\n",
    "\n",
    "        @function_tool\n",
    "        def retrieve(query: str) -> str:\n",
    "            \"\"\"Search Hugging Face docs for technical info, APIs, commands, and examples.\n",
    "            Use exact terms (e.g., \"from_pretrained\", \"ESPnet upload\", \"torchrun\"). \n",
    "            Try 2-3 targeted searches: specific terms → tool names → alternatives.\"\"\"\n",
    "            docs = self.retriever.retrieve(query, self.default_k)\n",
    "            if not docs:\n",
    "                return f\"No documents found for '{query}'. Try different search terms or break down the query into smaller parts.\"\n",
    "            return \"\\n\\n\".join([f\"Doc {i}: {doc.page_content}\" for i, doc in enumerate(docs, 1)])\n",
    "\n",
    "        self._agent = Agent(\n",
    "            name=\"RAG Assistant\",\n",
    "            model=self.model,\n",
    "            instructions=\"Search with exact terms first (commands, APIs, tool names). Try 2-3 different searches if needed. Only answer from retrieved documents. Preserve exact syntax and technical details.\",\n",
    "            tools=[retrieve]\n",
    "        )\n",
    "\n",
    "    async def _agentic_query(self, question: str, top_k: int) -> Dict[str, Any]:\n",
    "        \"\"\"Handle agentic mode: agent controls retrieval strategy.\"\"\"\n",
    "        try:\n",
    "            from agents import Runner\n",
    "        except ImportError:\n",
    "            raise ImportError(\"agents package required for agentic mode\")\n",
    "        \n",
    "        # Let agent handle the retrieval and reasoning\n",
    "        result = await Runner.run(self._agent, input=question)\n",
    "        \n",
    "        # In agentic mode, the agent controls retrieval internally\n",
    "        # so we don't return specific retrieved documents\n",
    "        return {\n",
    "            \"answer\": result.final_output,\n",
    "            \"retrieved_documents\": [],  # Agent handles retrieval internally\n",
    "            \"num_retrieved\": 0,  # Cannot determine exact count from agent execution\n",
    "        }\n",
    "\n",
    "    async def query(self, question: str, top_k: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Query the RAG system.\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.default_k\n",
    "            \n",
    "        try:\n",
    "            if self.mode == \"naive\":\n",
    "                return await self._naive_query(question, top_k)\n",
    "            elif self.mode == \"agentic\":\n",
    "                return await self._agentic_query(question, top_k)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode: {self.mode}\")\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"answer\": f\"Error: {str(e)}\", \n",
    "                \"retrieved_documents\": [], \n",
    "                \"num_retrieved\": 0,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ade81",
   "metadata": {},
   "source": [
    "Unlike naive mode's single retrieval call, the agent autonomously decides when and how to search - trying multiple keyword combinations until it finds sufficient context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2af7c",
   "metadata": {},
   "source": [
    "Run the Agentic RAG app for a sample query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "retriever = BM25Retriever()\n",
    "\n",
    "# Switch to agentic mode\n",
    "rag_agentic = ImprovedRAG(openai_client, retriever, mode=\"agentic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c10be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: It's the x86_64 architecture — specifically the \"x86_64-unknown-linux-musl\" binary.\n"
     ]
    }
   ],
   "source": [
    "question = \"What architecture is the `tokenizers-linux-x64-musl` binary designed for?\"\n",
    "result = await rag_agentic.query(question)\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba9aae",
   "metadata": {},
   "source": [
    "## Run experiment again and compare results\n",
    "Now let's evaluate the agentic RAG approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b032a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|██████████| 66/66 [01:27<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 58/66 passed (87.9%)\n",
      "\n",
      "Detailed results:\n",
      "Experiment(name=20251111-231055_agenticrag,  len=66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required components\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "async def run_agentic_evaluation():\n",
    "    # Download and prepare dataset\n",
    "    dataset_path = download_and_save_dataset()\n",
    "    dataset = create_ragas_dataset(dataset_path)\n",
    "\n",
    "    # Initialize RAG components with agentic mode\n",
    "    openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    retriever = BM25Retriever()\n",
    "    rag = ImprovedRAG(llm_client=openai_client, retriever=retriever, model=\"gpt-5-mini\", mode=\"agentic\")\n",
    "    llm = llm_factory('gpt-4o-mini', client=openai_client)\n",
    "\n",
    "    # Run evaluation experiment\n",
    "    exp_name = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_agenticrag\"\n",
    "    results = await evaluate_rag.arun(\n",
    "        dataset, \n",
    "        name=exp_name,\n",
    "        rag=rag,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    if results:\n",
    "        pass_count = sum(1 for result in results if result.get(\"correctness_score\") == \"pass\")\n",
    "        total_count = len(results)\n",
    "        pass_rate = (pass_count / total_count) * 100 if total_count > 0 else 0\n",
    "        print(f\"Results: {pass_count}/{total_count} passed ({pass_rate:.1f}%)\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the agentic evaluation\n",
    "results = await run_agentic_evaluation()\n",
    "print(\"\\nDetailed results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0e8d4",
   "metadata": {},
   "source": [
    "Excellent! We achieved a significant improvement from `65.2%` (naive) to `87.9%` (agentic) - that's a `22.7` percentage point improvement with the agentic RAG approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f297cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
